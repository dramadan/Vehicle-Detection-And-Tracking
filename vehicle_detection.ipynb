{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "from skimage.feature import hog\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Analyze_data():\n",
    "    #cars\n",
    "    directory = 'vehicles/'\n",
    "    folders = os.listdir(directory)\n",
    "    cars = []\n",
    "    for imtype in folders:\n",
    "        cars.extend(glob.glob(directory+imtype+'/*'))\n",
    "    print ('Number of cars = ', len(cars))\n",
    "    with open(\"cars.txt\", 'w') as f:\n",
    "        for fn in cars:\n",
    "            f.write(fn + '\\n')\n",
    "    #Not cars \n",
    "    directory = 'non-vehicles/'\n",
    "    folders = os.listdir(directory)\n",
    "    notcars = []\n",
    "    for imtype in folders:\n",
    "        notcars.extend(glob.glob(directory+imtype+'/*'))\n",
    "    print ('Number of non-cars = ', len(notcars))\n",
    "    with open(\"notcars.txt\", 'w') as f:\n",
    "        for fn in notcars:\n",
    "            f.write(fn + '\\n')\n",
    "    return cars, notcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cars =  8792\n",
      "Number of non-cars =  8968\n"
     ]
    }
   ],
   "source": [
    "cars, notcars = Analyze_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    # Return the feature vector\n",
    "    return np.hstack((color1, color2, color3))\n",
    "\n",
    "#compute color histogram features  \n",
    "def color_hist(img, nbins=32):\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features\n",
    "\n",
    "#Get HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs,spatial_size=(32, 32),hist_bins=32, orient=9,pix_per_cell=8,cell_per_block=2):    \n",
    "    # Create a list to append feature vectors\n",
    "    features = []\n",
    "    print (\"total images to train is \", len(imgs))\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        #Read image \n",
    "        img = mpimg.imread(file)\n",
    "        # apply color conversion\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        file_features.append(spatial_features)\n",
    "        # Apply color_hist()\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        file_features.append(hist_features)\n",
    "        hog_features = []\n",
    "        for channel in range(3):\n",
    "            hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))  \n",
    "        hog_features = np.ravel(hog_features)\n",
    "        # Append the new feature vector to the features list\n",
    "        file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images to train is  1000\n",
      "total images to train is  1000\n",
      "8.190794706344604 Seconds to compute features\n"
     ]
    }
   ],
   "source": [
    "#Training of LSVM\n",
    "orient_val = 9\n",
    "pix_per_cell_val = 8\n",
    "cell_per_block_val = 2\n",
    "spatial_size_val = (32,32)\n",
    "hist_bins_val = 32\n",
    "t = time.time()\n",
    "n_samples = 1000\n",
    "random_idxs = np.random.randint(0, len(cars), n_samples)\n",
    "test_cars = np.array(cars)[random_idxs]\n",
    "test_notcars = np.array(notcars)[random_idxs]\n",
    "car_features = extract_features(test_cars, spatial_size=spatial_size_val, hist_bins= hist_bins_val,\n",
    "                        orient=orient_val, pix_per_cell =pix_per_cell_val, cell_per_block = cell_per_block_val)\n",
    "\n",
    "not_car_features = extract_features(test_notcars, spatial_size=spatial_size_val, hist_bins= hist_bins_val,\n",
    "                        orient=orient_val, pix_per_cell =pix_per_cell_val, cell_per_block = cell_per_block_val)\n",
    "\n",
    "print (time.time() - t, 'Seconds to compute features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9  orientations \n",
      "pix_per_cell =  8 \n",
      "cell_per_block =  2 \n",
      "hist_bins =  32 \n",
      "spatial_size =  (32, 32)\n",
      "Feature vector length; 8460\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scalar = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaledX = X_scalar.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0,100)\n",
    "split_size = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaledX, y, test_size = split_size, random_state = rand_state)\n",
    "\n",
    "print (\"Using\", orient_val, \" orientations\", '\\npix_per_cell = ', pix_per_cell_val, '\\ncell_per_block = ', cell_per_block_val\n",
    "      , \"\\nhist_bins = \", hist_bins_val, \"\\nspatial_size = \", spatial_size_val)\n",
    "\n",
    "print ('Feature vector length;', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.97 training time\n",
      "Test accuracy is 0.995\n"
     ]
    }
   ],
   "source": [
    "    t = time.time()\n",
    "    # Use a linear SVC\n",
    "    svc=LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    t = time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    print (round(time.time()-t,2), 'training time')\n",
    "    # Check the score of the SVC\n",
    "    accuracy = round(svc.score(X_test, y_test),4)\n",
    "    print (\"Test accuracy is\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #save the model here \n",
    "    train_model_file = \"classifier.p\" \n",
    "    output = open(train_model_file, 'wb')\n",
    "    pickle.dump(svc, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    trained_model_file = \"classifier.p\"\n",
    "    with open(trained_model_file, mode='rb') as f:\n",
    "        svc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.995\n"
     ]
    }
   ],
   "source": [
    "acc1 = round(svc.score(X_test, y_test),4)\n",
    "print (\"Test accuracy is\", acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    all_box = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 3)\n",
    "        all_box.append(bbox)\n",
    "\n",
    "    return img, all_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    scale_choose = [1.3, 1.5, 1.8]\n",
    "    draw_img = np.copy(img)\n",
    "    count_window = 0\n",
    "    ystart = 400\n",
    "    ystop = 720\n",
    "    heatmap = np.zeros_like(img[:,:,0])\n",
    "    img = img.astype(np.float32)/255\n",
    "    for scale in scale_choose:\n",
    "        img_tosearch = img[ystart:ystop,:,:]\n",
    "        ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "        # Compute individual channel HOG features for the entire\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "        \n",
    "        nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "        nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "        nfeat_per_block = orient*cell_per_block**2\n",
    "        \n",
    "        window = 64\n",
    "        nblocks_per_window = (window // pix_per_cell)-1 \n",
    "        if scale == 1.8:\n",
    "            cells_per_step = 3\n",
    "        else:\n",
    "            cells_per_step = 2\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                # Extract HOG for this patch\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "                # Get color features\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "                # Scale features and make a prediction\n",
    "                test_features = X_scalar.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "                #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "                test_prediction = svc.predict(test_features)\n",
    "\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                    heatmap[ytop_draw+ystart:ytop_draw+win_draw+ystart, xbox_left:xbox_left+win_draw] += 1\n",
    "                count_window += 1\n",
    "        if vehicle_detected.first_frame == True:\n",
    "            print (\"For scale of  \", scale, \", the number of windows = \", count_window)\n",
    "        count_window = 0\n",
    "    return draw_img, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Car():\n",
    "    def __init__(self):\n",
    "        #Previous frames heatmaps\n",
    "        self.heatmap = np.array([None]*10)\n",
    "        #first frame \n",
    "        self.first_frame = True\n",
    "        self.smoothened = 10\n",
    "global vehicle_detected\n",
    "vehicle_detected = Car()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    spatial_size = (32,32)\n",
    "    hist_bins = 32\n",
    "    out_img, heatmap = find_cars(image, svc, X_scalar, orient,\n",
    "                        pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    \n",
    "    if vehicle_detected.first_frame == True:\n",
    "        applied_threshold = apply_threshold(np.copy(heatmap), 1)\n",
    "        #make the history same as the first frame\n",
    "        vehicle_detected.heatmap = np.array([applied_threshold] * vehicle_detected.smoothened)\n",
    "        vehicle_detected.first_frame = False\n",
    "        labels = label(applied_threshold)\n",
    "    else:    \n",
    "        #look into previous frames   \n",
    "        vehicle_detected.heatmap[0:-1] = vehicle_detected.heatmap[1:]\n",
    "        vehicle_detected.heatmap[-1] = heatmap\n",
    "        new_previous_frame_threshold = vehicle_detected.heatmap.sum(axis=0)\n",
    "        applied_threshold = apply_threshold(np.copy(new_previous_frame_threshold), vehicle_detected.smoothened*2+5)\n",
    "        labels = label(applied_threshold)\n",
    "        \n",
    "    draw_labeled, bbox = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    vehicle_detected.heatmap[-1] = add_heat(vehicle_detected.heatmap[-1], bbox)\n",
    "  \n",
    "    return draw_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For scale of   1.3 , the number of windows =  627\n",
      "For scale of   1.5 , the number of windows =  441\n",
      "For scale of   1.8 , the number of windows =  104\n",
      "[MoviePy] >>>> Building video result.mp4\n",
      "[MoviePy] Writing video result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [25:01<00:01,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result.mp4 \n",
      "\n",
      "Wall time: 25min 1s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"900\" height=\"540\" controls>\n",
       "  <source src=\"result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"900\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
